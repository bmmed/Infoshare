# Do not remove this line, otherwise mod_rewrite rules will stop working
RewriteBase /

# 6G FIREWALL/BLACKLIST
# @ https://perishablepress.com/6g/

# 6G:[QUERY STRINGS]
<IfModule mod_rewrite.c>
	RewriteEngine On
	RewriteCond %{QUERY_STRING} (eval\() [NC,OR]
	RewriteCond %{QUERY_STRING} (127\.0\.0\.1) [NC,OR]
	RewriteCond %{QUERY_STRING} ([a-z0-9]{2000}) [NC,OR]
	RewriteCond %{QUERY_STRING} (javascript:)(.*)(;) [NC,OR]
	RewriteCond %{QUERY_STRING} (base64_encode)(.*)(\() [NC,OR]
	RewriteCond %{QUERY_STRING} (GLOBALS|REQUEST)(=|\[|%) [NC,OR]
	RewriteCond %{QUERY_STRING} (<|%3C)(.*)script(.*)(>|%3) [NC,OR]
	RewriteCond %{QUERY_STRING} (\\|\.\.\.|\.\./|~|`|<|>|\|) [NC,OR]
	RewriteCond %{QUERY_STRING} (boot\.ini|etc/passwd|self/environ) [NC,OR]
	RewriteCond %{QUERY_STRING} (thumbs?(_editor|open)?|tim(thumb)?)\.php [NC,OR]
	RewriteCond %{QUERY_STRING} (\'|\")(.*)(drop|insert|md5|select|union) [NC]
	RewriteRule .* - [F]
</IfModule>

# 6G:[REQUEST METHOD]
<IfModule mod_rewrite.c>
	RewriteCond %{REQUEST_METHOD} ^(connect|debug|delete|move|put|trace|track) [NC]
	RewriteRule .* - [F]
</IfModule>

# 6G:[REFERRERS]
<IfModule mod_rewrite.c>
	RewriteCond %{HTTP_REFERER} ([a-z0-9]{2000}) [NC,OR]
	RewriteCond %{HTTP_REFERER} (semalt.com|todaperfeita) [NC]
	RewriteRule .* - [F]
</IfModule>

# 6G:[REQUEST STRINGS]
<IfModule mod_alias.c>
	RedirectMatch 403 (?i)([a-z0-9]{2000})
	RedirectMatch 403 (?i)(https?|ftp|php):/
	RedirectMatch 403 (?i)(base64_encode)(.*)(\()
	RedirectMatch 403 (?i)(=\\\'|=\\%27|/\\\'/?)\.
	RedirectMatch 403 (?i)/(\$(\&)?|\*|\"|\.|,|&|&amp;?)/?$
	RedirectMatch 403 (?i)(\{0\}|\(/\(|\.\.\.|\+\+\+|\\\"\\\")
	RedirectMatch 403 (?i)(~|`|<|>|:|;|,|%|\\|\s|\{|\}|\[|\]|\|)
	RedirectMatch 403 (?i)/(=|\$&|_mm|cgi-|etc/passwd|muieblack)
	RedirectMatch 403 (?i)(&pws=0|_vti_|\(null\)|\{\$itemURL\}|echo(.*)kae|etc/passwd|eval\(|self/environ)
	RedirectMatch 403 (?i)\.(aspx?|bash|bak?|cfg|cgi|dll|exe|git|hg|ini|jsp|log|mdb|out|sql|svn|swp|tar|rar|rdf)$
	RedirectMatch 403 (?i)/(^$|(wp-)?config|mobiquo|phpinfo|shell|sqlpatch|thumb|thumb_editor|thumbopen|timthumb|webshell)\.php
</IfModule>

# 6G:[USER AGENTS]
<IfModule mod_setenvif.c>
	SetEnvIfNoCase User-Agent ([a-z0-9]{2000}) bad_bot
	SetEnvIfNoCase User-Agent (archive.org|binlar|casper|checkpriv|choppy|clshttp|cmsworld|diavol|dotbot|extract|feedfinder|flicky|g00g1e|harvest|heritrix|httrack|kmccrew|loader|miner|nikto|nutch|planetwork|postrank|purebot|pycurl|python|seekerspider|siclab|skygrid|sqlmap|sucker|turnit|vikspider|winhttp|xxxyy|youda|zmeu|zune) bad_bot
	<limit GET POST PUT>
		Order Allow,Deny
		Allow from All
		Deny from env=bad_bot
	</limit>
</IfModule>

# 6G:[BAD IPS]
<Limit GET HEAD OPTIONS POST PUT>
	Order Allow,Deny
	Allow from All
	# uncomment/edit/repeat next line to block IPs
	# Deny from 123.456.789
</Limit>

<?
function areyouabot()
{
   
global $HTTP_SERVER_VARS;

   $RobotsList = array (
   "antibot",
   "appie",
   "architext",
   "bjaaland",
   "digout4u",
   "echo",
   "fast-webcrawler",
   "ferret",
   "googlebot",
   "gulliver",
   "harvest",
   "htdig",
   "ia_archiver",
   "jeeves",
   "jennybot",
   "linkwalker",
   "lycos",
   "mercator",
   "moget",
   "muscatferret",
   "myweb",
   "netcraft",
   "nomad",
   "petersnews",
   "scooter",
   "slurp",
   "unlost_web_crawler",
   "voila",
   "voyager",
   "webbase",
   "weblayers",
   "wget",
   "wisenutbot",
   "acme.spider",
   "ahoythehomepagefinder",
   "alkaline",
   "arachnophilia",
   "aretha",
   "ariadne",
   "arks",
   "aspider",
   "atn.txt",
   "atomz",
   "auresys",
   "backrub",
   "bigbrother",
   "blackwidow",
   "blindekuh",
   "bloodhound",
   "brightnet",
   "bspider",
   "cactvschemistryspider",
   "cassandra",
   "cgireader",
   "checkbot",
   "churl",
   "cmc",
   "collective",
   "combine",
   "conceptbot",
   "coolbot",
   "core",
   "cosmos",
   "cruiser",
   "cusco",
   "cyberspyder",
   "deweb",
   "dienstspider",
   "digger",
   "diibot",
   "directhit",
   "dnabot",
   "download_express",
   "dragonbot",
   "dwcp",
   "e-collector",
   "ebiness",
   "eit",
   "elfinbot",
   "emacs",
   "emcspider",
   "esther",
   "evliyacelebi",
   "nzexplorer",
   "fdse",
   "felix",
   "fetchrover",
   "fido",
   "finnish",
   "fireball",
   "fouineur",
   "francoroute",
   "freecrawl",
   "funnelweb",
   "gama",
   "gazz",
   "gcreep",
   "getbot",
   "geturl",
   "golem",
   "grapnel",
   "griffon",
   "gromit",
   "hambot",
   "havindex",
   "hometown",
   "htmlgobble",
   "hyperdecontextualizer",
   "iajabot",
   "ibm",
   "iconoclast",
   "ilse",
   "imagelock",
   "incywincy",
   "informant",
   "infoseek",
   "infoseeksidewinder",
   "infospider",
   "inspectorwww",
   "intelliagent",
   "irobot",
   "iron33",
   "israelisearch",
   "javabee",
   "jbot",
   "jcrawler",
   "jobo",
   "jobot",
   "joebot",
   "jubii",
   "jumpstation",
   "katipo",
   "kdd",
   "kilroy",
   "ko_yappo_robot",
   "labelgrabber.txt",
   "larbin",
   "legs",
   "linkidator",
   "linkscan",
   "lockon",
   "logo_gif",
   "macworm",
   "magpie",
   "marvin",
   "mattie",
   "mediafox",
   "merzscope",
   "meshexplorer",
   "mindcrawler",
   "momspider",
   "monster",
   "motor",
   "mwdsearch",
   "netcarta",
   "netmechanic",
   "netscoop",
   "newscan-online",
   "nhse",
   "northstar",
   "occam",
   "octopus",
   "openfind",
   "orb_search",
   "packrat",
   "pageboy",
   "parasite",
   "patric",
   "pegasus",
   "perignator",
   "perlcrawler",
   "phantom",
   "piltdownman",
   "pimptrain",
   "pioneer",
   "pitkow",
   "pjspider",
   "pka",
   "plumtreewebaccessor",
   "poppi",
   "portalb",
   "puu",
   "python",
   "raven",
   "rbse",
   "resumerobot",
   "rhcs",
   "roadrunner",
   "robbie",
   "robi",
   "robofox",
   "robozilla",
   "roverbot",
   "rules",
   "safetynetrobot",
   "search_au",
   "searchprocess",
   "senrigan",
   "sgscout",
   "shaggy",
   "shaihulud",
   "sift",
   "simbot",
   "site-valet",
   "sitegrabber",
   "sitetech",
   "slcrawler",
   "smartspider",
   "snooper",
   "solbot",
   "spanner",
   "speedy",
   "spider_monkey",
   "spiderbot",
   "spiderline",
   "spiderman",
   "spiderview",
   "spry",
   "ssearcher",
   "suke",
   "suntek",
   "sven",
   "tach_bw",
   "tarantula",
   "tarspider",
   "techbot",
   "templeton",
   "teoma_agent1",
   "titin",
   "titan",
   "tkwww",
   "tlspider",
   "ucsd",
   "udmsearch",
   "urlck",
   "valkyrie",
   "victoria",
   "visionsearch",
   "vwbot",
   "w3index",
   "w3m2",
   "wallpaper",
   "wanderer",
   "wapspider",
   "webbandit",
   "webcatcher",
   "webcopy",
   "webfetcher",
   "webfoot",
   "weblinker",
   "webmirror",
   "webmoose",
   "webquest",
   "webreader",
   "webreaper",
   "websnarf",
   "webspider",
   "webvac",
   "webwalk",
   "webwalker",
   "webwatch",
   "whatuseek",
   "whowhere",
   "wired-digital",
   "wmir",
   "wolp",
   "wombat",
   "worm",
   "wwwc",
   "wz101",
   "xget",
   "awbot",
   "bobby",
   "boris",
   "bumblebee",
   "cscrawler",
   "daviesbot",
   "ezresult",
   "gigabot",
   "gnodspider",
   "internetseer",
   "justview",
   "linkbot",
   "linkchecker",
   "nederland.zoek",
   "perman",
   "pompos",
   "pooodle",
   "redalert",
   "shoutcast",
   "slysearch",
   "ultraseek",
   "webcompass",
   "yandex",
   "robot",
   "bot",
   "psbot",
   "crawl"
   );

   $botID = strtolower($HTTP_SERVER_VARS['HTTP_USER_AGENT']);
   $iamabot = 0;
   for ($i = 0; $i < count($RobotsList); $i++)
   {
       
      if ( strstr($botID, $RobotsList[$i]) )
      {
         $iamabot = 1;
         return $iamabot;
      }
       
   }
   return $iamabot;
   
} 


if (areyouabot()) { 
die("Erreur, vous ne pouvez pas aspirer ce site"); 
}


?>